Action: [[ 0 10  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Training completed and model saved.
Model loaded from saved state.
Action: [[0 8 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 20  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[ 0 17  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -2
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 15  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 21  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0.06451612903225806
2
Action: [[ 0 14  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0.07752538956508256
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 16  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 23  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[0 7 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0.03876269478254128
2
Training completed and model saved.
Model loaded from saved state.
Action: [[0 9 0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 26  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[ 0 20  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -2
2
Training completed and model saved.
Model loaded from saved state.
Action: [[0 6 0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[0 8 0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[0 7 0]]
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 27  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 17  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[0 4 0]]
2
Training completed and model saved.
Model loaded from saved state.
Action: [[0 1 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 17  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[0 0 0]]
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 24  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 25  0]]
2
Action: [[ 0 14  0]]
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 16  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 27  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[0 1 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -2
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 20  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[0 4 0]]
2
Action: [[0 0 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0.03876269478254128
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 19  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[0 3 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[ 0 25  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0.03876269478254128
2
Training completed and model saved.
Model loaded from saved state.
Action: [[0 7 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0.18642803877703204
2
Action: [[ 0 10  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[0 5 0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 20  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 10  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[0 1 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -2
2
Training completed and model saved.
Model loaded from saved state.
Action: [[0 6 0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[0 0 0]]
2
Action: [[ 0 18  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0.03876269478254128
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 21  0]]
2
Action: [[0 6 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 21  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0.03876269478254128
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 23  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[0 9 0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[ 0 25  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0.03876269478254128
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 21  0]]
2
Action: [[0 1 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 17  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 10  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 22  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[0 5 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -2
2
Training completed and model saved.
Model loaded from saved state.
Action: [[0 6 0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 27  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[ 0 14  0]]
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 15  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 14  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0.06451612903225806
2
Action: [[ 0 13  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 10  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[0 4 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0.06451612903225806
2
Action: [[ 0 24  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Training completed and model saved.
Model loaded from saved state.
Action: [[0 5 0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 21  0]]
2
Action: [[ 0 13  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 11  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0.18642803877703204
2
Action: [[0 5 0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 16  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 20  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 25  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0.06451612903225806
2
Action: [[ 0 22  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 27  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 22  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[0 4 0]]
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 23  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 24  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[0 4 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0.0
2
Training completed and model saved.
Model loaded from saved state.
Action: [[0 5 0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 21  0]]
2
Action: [[ 0 18  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0.03876269478254128
2
Training completed and model saved.
Model loaded from saved state.
Action: [[0 7 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0.18642803877703204
2
Action: [[ 0 21  0]]
2
Action: [[ 0 18  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0.07752538956508256
2
Training completed and model saved.
Model loaded from saved state.
Action: [[0 3 0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 25  0]]
2
Action: [[ 0 20  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 25  0]]
2
Action: [[0 4 0]]
2
Action: [[ 0 16  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 17  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[0 9 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[ 0 21  0]]
2
Training completed and model saved.
Model loaded from saved state.
Action: [[0 6 0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 19  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[0 4 0]]
2
Training completed and model saved.
Model loaded from saved state.
Action: [[0 1 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 17  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[ 0 19  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -2
2
Training completed and model saved.
Model loaded from saved state.
Action: [[0 9 0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[0 6 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[ 0 14  0]]
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 24  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 25  0]]
2
Action: [[ 0 19  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 15  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[0 8 0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[ 0 16  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -2
2
Training completed and model saved.
Model loaded from saved state.
Action: [[0 6 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 20  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[ 0 10  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -2
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 15  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 25  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0.06451612903225806
2
Action: [[0 0 0]]
2
Training completed and model saved.
Model loaded from saved state.
Action: [[0 1 0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[0 2 0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[ 0 13  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -2
2
Training completed and model saved.
Model loaded from saved state.
Action: [[0 1 0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[0 1 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[ 0 17  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -2
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 27  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[0 9 0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[ 0 12  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -2
2
Training completed and model saved.
Model loaded from saved state.
Action: [[0 5 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[0 3 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[ 0 13  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -2
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 14  0]]
2
Action: [[ 0 13  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 15  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 24  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 14  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0.06451612903225806
2
Action: [[ 0 17  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 10  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 22  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[ 0 27  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -2
2
Training completed and model saved.
Model loaded from saved state.
Action: [[0 2 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 11  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0.06451612903225806
2
Action: [[ 0 16  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Training completed and model saved.
Model loaded from saved state.
Action: [[0 4 0]]
2
Action: [[ 0 26  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 14  0]]
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 23  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 17  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[0 4 0]]
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 15  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[0 0 0]]
2
Action: [[0 2 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 27  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[0 1 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[0 9 0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -2
2
Training completed and model saved.
Model loaded from saved state.
Action: [[0 5 0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[0 9 0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[ 0 11  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0.03876269478254128
2
Training completed and model saved.
Model loaded from saved state.
Action: [[0 3 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[0 1 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[0 3 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -2
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 23  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[0 0 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0.06451612903225806
2
Action: [[ 0 26  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Training completed and model saved.
Model loaded from saved state.
Action: [[0 1 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[0 7 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0.06451612903225806
2
Action: [[0 4 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0.03876269478254128
2
Training completed and model saved.
Model loaded from saved state.
Action: [[0 0 0]]
2
Action: [[ 0 18  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0.06451612903225806
2
Action: [[ 0 25  0]]
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 22  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 12  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[ 0 24  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -2
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 23  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[0 0 0]]
2
Action: [[ 0 12  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Training completed and model saved.
Model loaded from saved state.
Action: [[0 7 0]]
2
Action: [[ 0 12  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 17  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 10  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[0 6 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[0 9 0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -2
2
Training completed and model saved.
Model loaded from saved state.
Action: [[0 0 0]]
2
Action: [[0 0 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0.06451612903225806
2
Action: [[ 0 15  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Training completed and model saved.
Model loaded from saved state.
Action: [[0 5 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[0 7 0]]
2
Action: [[ 0 24  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 11  0]]
2
Action: [[ 0 19  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 20  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 22  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 10  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[0 8 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -2
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 26  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 14  0]]
2
Action: [[ 0 21  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0.03876269478254128
2
Training completed and model saved.
Model loaded from saved state.
Action: [[0 7 0]]
2
Action: [[0 2 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 16  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Training completed and model saved.
Model loaded from saved state.
Action: [[0 0 0]]
2
Action: [[ 0 27  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 10  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 26  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 10  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[ 0 14  0]]
2
Training completed and model saved.
Model loaded from saved state.
Action: [[0 0 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0.18642803877703204
2
Action: [[0 3 0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 22  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 16  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 15  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[ 0 11  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0.03876269478254128
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 21  0]]
2
Action: [[ 0 22  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 24  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 20  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[0 4 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0.06451612903225806
2
Action: [[0 4 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0.0
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 23  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 16  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[ 0 13  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -2
2
Training completed and model saved.
Model loaded from saved state.
Action: [[0 0 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0.18642803877703204
2
Action: [[ 0 10  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 26  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Training completed and model saved.
Model loaded from saved state.
Action: [[0 3 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 25  0]]
2
Action: [[0 5 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Training completed and model saved.
Model loaded from saved state.
Action: [[0 7 0]]
2
Action: [[ 0 15  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 12  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 12  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 24  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[ 0 17  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -2
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 24  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 14  0]]
2
Action: [[0 4 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0.0
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 15  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[0 6 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[ 0 23  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -2
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 10  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[0 3 0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[0 7 0]]
2
Training completed and model saved.
Model loaded from saved state.
Action: [[0 5 0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[0 9 0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[ 0 14  0]]
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 14  0]]
2
Action: [[0 1 0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[0 9 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 12  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 25  0]]
2
Action: [[0 8 0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 19  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 22  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[0 0 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0.03876269478254128
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 15  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 22  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[ 0 12  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -2
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 17  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[0 4 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0.06451612903225806
2
Action: [[0 7 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0.03876269478254128
2
Training completed and model saved.
Model loaded from saved state.
Action: [[0 6 0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 15  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[ 0 11  0]]
2
Training completed and model saved.
Model loaded from saved state.
Action: [[0 3 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 24  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[ 0 20  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -2
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 10  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[0 8 0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[ 0 27  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -2
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 22  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[0 3 0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[ 0 14  0]]
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 23  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[0 2 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[ 0 15  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -2
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 26  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 17  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[ 0 27  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -2
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 18  0]]
2
Action: [[ 0 23  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 10  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Training completed and model saved.
Model loaded from saved state.
Action: [[0 9 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 16  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[ 0 20  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -2
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 13  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 21  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0.06451612903225806
2
Action: [[0 5 1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 24  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 26  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[ 0 15  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -2
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 15  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[0 1 0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[ 0 19  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -2
2
Training completed and model saved.
Model loaded from saved state.
Action: [[ 0 26  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  0
2
Action: [[ 0 13  1]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -1
2
Action: [[ 0 27  0]]
<<<<<<<<<<<<Giving reward>>>>>>>>>>>>:  -2
2
Training completed and model saved.
(.venv) saisurisetti@SAIS-MBP server-fleet-management % 